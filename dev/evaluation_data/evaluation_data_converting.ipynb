{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3de5321-6aad-42b3-bae2-df5498595b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.data.path.append(\"./nltk_data\")\n",
    "from nltk.corpus import wordnet as wn\n",
    "from typing import List, Dict, Union, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a53127c-a3b7-4cc2-bad2-0d8a587a25ad",
   "metadata": {},
   "source": [
    "> Conversion of the original sense notation format into synsets used in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b4cda4-b6e3-4b47-8148-f8171a5d25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sense_key_to_synset_name(sense_key_str: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Converts a string of Sense Keys (separated by ';') into a list of Synset names.\n",
    "    Example: \"art%1:09:00::\" -> [\"art.n.03\"]\n",
    "    \"\"\"\n",
    "    keys = sense_key_str.split(';')\n",
    "    synset_names = []\n",
    "    \n",
    "    for key in keys:\n",
    "        try:\n",
    "            # Retrieve the lemma object using the sense key\n",
    "            lemma = wn.lemma_from_key(key)\n",
    "            # Get the synset associated with this lemma\n",
    "            synset = lemma.synset()\n",
    "            synset_names.append(synset.name())\n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    # Remove duplicates if multiple keys map to the same synset\n",
    "    return list(set(synset_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0c2421-c498-48ac-945b-230acea84352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['art.n.03']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get synset name \"art%1:09:00::\"\n",
    "sense_key_str = \"art%1:09:00::\"\n",
    "sense_key_to_synset_name(sense_key_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc49a30-4bea-4101-95c2-c32522088e1f",
   "metadata": {},
   "source": [
    "> Conversion of the original target word indication format to the start and end character indices used in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77aed44-8947-4862-8d6f-aabcb0214095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_offsets(sentence: str, token_start: int, token_end: int) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Calculates character start and end indices based on token indices.\n",
    "    \"\"\"\n",
    "    tokens = sentence.split(' ')\n",
    "    \n",
    "    # We need to find the character position of the token at index \"token_start\"\n",
    "    current_char_idx = 0\n",
    "    target_char_start = -1\n",
    "    target_char_end = -1\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        token_len = len(token)\n",
    "        \n",
    "        if i == token_start:\n",
    "            target_char_start = current_char_idx\n",
    "        \n",
    "        # If we are at the last token of the target phrase\n",
    "        if i == token_end - 1:\n",
    "            target_char_end = current_char_idx + token_len\n",
    "            break\n",
    "        \n",
    "        # Advance cursor: token length + 1 for space\n",
    "        current_char_idx += token_len + 1\n",
    "        \n",
    "    return target_char_start, target_char_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d4ceed-9067-4ac5-a6ba-89ff2f46fc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get indicies for \"old age\"\n",
    "sentence = \"Mr. Hammond worries that old age and the flightiness of youth will diminish the ranks of the East Anglian group that keeps the Aslacton bells pealing .\"\n",
    "token_start = 4\n",
    "token_end = 6\n",
    "get_char_offsets(sentence, token_start, token_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b01eeab-4707-4e1c-97b0-1616a71bb508",
   "metadata": {},
   "source": [
    "> Function for converting the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af104773-76d7-437c-9a8a-366673cb4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_benchmark_file(input_path: str, output_path: str):\n",
    "    \"\"\"\n",
    "    Reads the JSONL benchmark file, transforms data to the training format, and saves as Parquet.\n",
    "    \"\"\"\n",
    "\n",
    "    input_path = os.path.join(\"jsonl\", input_path)\n",
    "    data = []\n",
    "    \n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            record = json.loads(line)\n",
    "            \n",
    "            # 1. Parse Sentence and IDs\n",
    "            sent_text = record['sentence']\n",
    "            word_val = record['word']\n",
    "            \n",
    "            # 2. Convert Sense Keys to Synset Names (Gold Labels)\n",
    "            # We store this as a list because benchmarks can have multiple valid answers\n",
    "            gold_synsets = sense_key_to_synset_name(record['sense'])\n",
    "            \n",
    "            if not gold_synsets:\n",
    "                continue\n",
    "\n",
    "            # 3. Calculate Character Offsets\n",
    "            t_start = record['start']\n",
    "            t_end = record['end']\n",
    "            \n",
    "            c_start, c_end = get_char_offsets(sent_text, t_start, t_end)\n",
    "                        \n",
    "            # Create the row entry\n",
    "            row = {\n",
    "                'id': record['id'],\n",
    "                'sentence': sent_text,\n",
    "                'target_word': word_val,\n",
    "                'char_start': c_start,\n",
    "                'char_end': c_end,\n",
    "                'gold_synsets': gold_synsets, # List of valid strings, e.g. ['art.n.01']\n",
    "            }\n",
    "            data.append(row)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save to Parquet\n",
    "    df.to_parquet(output_path, index=False)\n",
    "    print(f\"Processed {input_path}: {len(df)} records saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ab083d3-793a-49a4-ae38-a42b896faf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed jsonl/ALL.jsonl: 7253 records saved to parquet/ALL.parquet\n",
      "Processed jsonl/semeval2007.jsonl: 455 records saved to parquet/semeval2007.parquet\n",
      "Processed jsonl/semeval2013.jsonl: 1644 records saved to parquet/semeval2013.parquet\n",
      "Processed jsonl/semeval2015.jsonl: 1022 records saved to parquet/semeval2015.parquet\n",
      "Processed jsonl/senseval2.jsonl: 2282 records saved to parquet/senseval2.parquet\n",
      "Processed jsonl/senseval3.jsonl: 1850 records saved to parquet/senseval3.parquet\n"
     ]
    }
   ],
   "source": [
    "files = [\"ALL.jsonl\", \"semeval2007.jsonl\", \"semeval2013.jsonl\", \"semeval2015.jsonl\", \"senseval2.jsonl\", \"senseval3.jsonl\"]\n",
    "\n",
    "output_dir = \"parquet\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for f in files:\n",
    "    output_filename = f.replace(\".jsonl\", \".parquet\")\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    process_benchmark_file(f, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa54793-128b-460e-bf47-9edd1cea09fd",
   "metadata": {},
   "source": [
    "> Conversion check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e6b99db-fabb-4609-b851-86be5c134640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"parquet/ALL.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c7ce1c3-59a2-4652-8d5c-cccc8b5d0e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>char_start</th>\n",
       "      <th>char_end</th>\n",
       "      <th>gold_synsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>senseval2.d000.s000.t000</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>art</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>[art.n.03]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>senseval2.d000.s000.t001</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>change-ringing</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>[change_ringing.n.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>senseval2.d000.s000.t002</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>peculiar</td>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>[peculiar.s.04, particular.s.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>senseval2.d000.s000.t003</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>English</td>\n",
       "      <td>45</td>\n",
       "      <td>52</td>\n",
       "      <td>[english.n.02]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>senseval2.d000.s000.t004</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>most</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>[most.a.01]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  senseval2.d000.s000.t000   \n",
       "1  senseval2.d000.s000.t001   \n",
       "2  senseval2.d000.s000.t002   \n",
       "3  senseval2.d000.s000.t003   \n",
       "4  senseval2.d000.s000.t004   \n",
       "\n",
       "                                            sentence     target_word  \\\n",
       "0  The art of change-ringing is peculiar to the E...             art   \n",
       "1  The art of change-ringing is peculiar to the E...  change-ringing   \n",
       "2  The art of change-ringing is peculiar to the E...        peculiar   \n",
       "3  The art of change-ringing is peculiar to the E...         English   \n",
       "4  The art of change-ringing is peculiar to the E...            most   \n",
       "\n",
       "   char_start  char_end                      gold_synsets  \n",
       "0           4         7                        [art.n.03]  \n",
       "1          11        25             [change_ringing.n.01]  \n",
       "2          29        37  [peculiar.s.04, particular.s.01]  \n",
       "3          45        52                    [english.n.02]  \n",
       "4          66        70                       [most.a.01]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f46252f-2b0d-4d50-9013-4dc6c470c884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>char_start</th>\n",
       "      <th>char_end</th>\n",
       "      <th>gold_synsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>senseval2.d000.s010.t000</td>\n",
       "      <td>They belong to a group of 15 ringers -- includ...</td>\n",
       "      <td>belong to</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>[belong_to.v.01]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  \\\n",
       "84  senseval2.d000.s010.t000   \n",
       "\n",
       "                                             sentence target_word  char_start  \\\n",
       "84  They belong to a group of 15 ringers -- includ...   belong to           5   \n",
       "\n",
       "    char_end      gold_synsets  \n",
       "84        14  [belong_to.v.01]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"id\"] == \"senseval2.d000.s010.t000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169d9462-e562-4b70-938b-09723430d60a",
   "metadata": {},
   "source": [
    "> The dataset contains gold_synsets lists and correctly stores cases with multiple answers, as well as correct indexes for targets containing multiple words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
