{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6db3c2a-a635-4f16-a192-dabe7a36a809",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Unmasked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c97a9-7b24-4c17-b8ac-4b828edf181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    DebertaV2PreTrainedModel, \n",
    "    DebertaV2Config\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from tqdm.notebook import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "174ed43e-3c3d-4477-a477-860abc76cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide false warnings from transformers\n",
    "import logging\n",
    "from transformers import logging as hf_logging\n",
    "hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10516a56-dcc9-4af0-91e1-f2490df3de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Custom Dataset Class ---\n",
    "class WSDDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        sentence = row['sentence']\n",
    "        c_start = row['char_start']\n",
    "        # c_end = row['char_end'] \n",
    "\n",
    "        # Tokenization with offset mapping\n",
    "        encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        offsets = encoding['offset_mapping'].squeeze().tolist()\n",
    "        target_token_idx = 0\n",
    "\n",
    "        # Find the token corresponding to the word start\n",
    "        for i, (o_start, o_end) in enumerate(offsets):\n",
    "            if o_start == 0 and o_end == 0: continue \n",
    "\n",
    "            if o_start == c_start:\n",
    "                target_token_idx = i\n",
    "                break\n",
    "\n",
    "            if o_start < c_start and o_end > c_start:\n",
    "                 target_token_idx = i\n",
    "                 break\n",
    "\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'target_token_idx': torch.tensor(target_token_idx, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "43ae7e0b-b601-4173-b2b7-b5e01807c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Custom Model Class ---\n",
    "class DebertaV3ForWSD(DebertaV2PreTrainedModel): \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.deberta = AutoModel.from_config(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, target_token_idx=None, labels=None, **kwargs):\n",
    "        kwargs.pop(\"num_items_in_batch\", None)\n",
    "\n",
    "        # Basic forward pass\n",
    "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "        batch_indices = torch.arange(batch_size, device=input_ids.device)\n",
    "        \n",
    "        # Extract vector for the specific target token\n",
    "        target_vectors = sequence_output[batch_indices, target_token_idx]\n",
    "\n",
    "        target_vectors = self.dropout(target_vectors)\n",
    "        logits = self.classifier(target_vectors)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        # Simplified return\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8bcb664d-21a6-4a15-9155-27e7eabf2f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Setup Paths and Device ---\n",
    "model_path = \"./models/deberta/deberta_wsd_custom\"\n",
    "test_data_path = \"./evaluation_data/parquet/ALL.parquet\"\n",
    "label_map_path = \"./label_map.json\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12459f78-5507-4c09-9828-71d397665eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Load Resources ---\n",
    "\n",
    "# Load Label Map (Label -> ID) and invert it (ID -> Label)\n",
    "with open(label_map_path, 'r', encoding='utf-8') as f:\n",
    "    label2id = json.load(f)\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Load Tokenizer and Config\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = DebertaV2Config.from_pretrained(model_path)\n",
    "\n",
    "# Load Model\n",
    "model = DebertaV3ForWSD.from_pretrained(model_path, config=config)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load Data\n",
    "df_test = pd.read_parquet(test_data_path)\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "test_dataset = WSDDataset(df_test, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "675f2bbe-0572-4f60-a4ef-3ee43cc7b2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac57ccb58ff44bb19af02a3cd7a74724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 5. Inference Loop ---\n",
    "all_preds = []\n",
    "\n",
    "print(\"Running inference...\")\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        target_token_idx = batch['target_token_idx'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            target_token_idx=target_token_idx\n",
    "        )\n",
    "        \n",
    "        # Get the ID with maximum probability\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09f3a925-a876-4870-a2ac-ddb75ecc8efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy: 0.5875 (4261/7253)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>gold_synsets</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>senseval2.d000.s000.t000</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>art</td>\n",
       "      <td>[art.n.03]</td>\n",
       "      <td>art.n.01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>senseval2.d000.s000.t001</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>change-ringing</td>\n",
       "      <td>[change_ringing.n.01]</td>\n",
       "      <td>change.n.03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>senseval2.d000.s000.t002</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>peculiar</td>\n",
       "      <td>[particular.s.01, peculiar.s.04]</td>\n",
       "      <td>particular.s.01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>senseval2.d000.s000.t003</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>English</td>\n",
       "      <td>[english.n.02]</td>\n",
       "      <td>english.n.01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>senseval2.d000.s000.t004</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>most</td>\n",
       "      <td>[most.a.01]</td>\n",
       "      <td>most.a.01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  senseval2.d000.s000.t000   \n",
       "1  senseval2.d000.s000.t001   \n",
       "2  senseval2.d000.s000.t002   \n",
       "3  senseval2.d000.s000.t003   \n",
       "4  senseval2.d000.s000.t004   \n",
       "\n",
       "                                            sentence     target_word  \\\n",
       "0  The art of change-ringing is peculiar to the E...             art   \n",
       "1  The art of change-ringing is peculiar to the E...  change-ringing   \n",
       "2  The art of change-ringing is peculiar to the E...        peculiar   \n",
       "3  The art of change-ringing is peculiar to the E...         English   \n",
       "4  The art of change-ringing is peculiar to the E...            most   \n",
       "\n",
       "                       gold_synsets  predicted_label  is_correct  \n",
       "0                        [art.n.03]         art.n.01       False  \n",
       "1             [change_ringing.n.01]      change.n.03       False  \n",
       "2  [particular.s.01, peculiar.s.04]  particular.s.01        True  \n",
       "3                    [english.n.02]     english.n.01       False  \n",
       "4                       [most.a.01]        most.a.01        True  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 6. Process Results ---\n",
    "results = []\n",
    "correct_count = 0\n",
    "total_count = len(df_test)\n",
    "\n",
    "# Iterate through original dataframe to build the result\n",
    "for idx, row in df_test.iterrows():\n",
    "    predicted_id = all_preds[idx]\n",
    "    \n",
    "    # Convert ID back to string label\n",
    "    if predicted_id in id2label:\n",
    "        predicted_label_str = id2label[predicted_id]\n",
    "    else:\n",
    "        predicted_label_str = \"UNKNOWN\" \n",
    "\n",
    "    # Check against gold synsets\n",
    "    gold_list = row['gold_synsets']\n",
    "    \n",
    "    # Check if prediction is in the list of correct answers\n",
    "    is_correct = predicted_label_str in gold_list\n",
    "    \n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "    \n",
    "    # Construct result row\n",
    "    res_row = row.drop(['char_start', 'char_end']).to_dict()\n",
    "    res_row['predicted_label'] = predicted_label_str\n",
    "    res_row['is_correct'] = is_correct\n",
    "    results.append(res_row)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0.0\n",
    "\n",
    "# Print Accuracy\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f} ({correct_count}/{total_count})\")\n",
    "\n",
    "# Create Final DataFrame\n",
    "final_df = pd.DataFrame(results)\n",
    "final_df['gold_synsets'] = final_df['gold_synsets'].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)\n",
    "final_df.to_csv(\"./results/unmasked_results.csv\", index=False)\n",
    "\n",
    "# Display first few rows\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a027f-0192-429c-862b-eea2ec64ed4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2d871951-5f62-4999-9979-083956dc8a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(\"./nltk_data\")\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65c46e8f-3cba-4823-9783-86bfb99a44fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Custom Dataset Class ---\n",
    "class WSDDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, label2id, max_len=128):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.label2id = label2id\n",
    "        self.num_labels = len(label2id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        sentence = row['sentence']\n",
    "        target_word = row['target_word']\n",
    "        c_start = row['char_start']\n",
    "        \n",
    "        # Tokenization with offset mapping\n",
    "        encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        offsets = encoding['offset_mapping'].squeeze().tolist()\n",
    "        target_token_idx = 0\n",
    "\n",
    "        # Find the token corresponding to the word start\n",
    "        for i, (o_start, o_end) in enumerate(offsets):\n",
    "            if o_start == 0 and o_end == 0: continue\n",
    "            if o_start == c_start:\n",
    "                target_token_idx = i\n",
    "                break\n",
    "            if o_start < c_start and o_end > c_start:\n",
    "                 target_token_idx = i\n",
    "                 break\n",
    "        \n",
    "        # --- Logit Masking Logic ---\n",
    "        # Initialize mask with large negative value\n",
    "        mask = torch.full((self.num_labels,), -1e4, dtype=torch.float32)\n",
    "        \n",
    "        # 1. Get candidate synsets from NLTK\n",
    "        lookup_word = target_word.replace(\" \", \"_\")\n",
    "        synsets = wn.synsets(lookup_word)\n",
    "        \n",
    "        found_candidates = False\n",
    "        valid_candidate_ids = [] # To store used candidates for report\n",
    "\n",
    "        # 2. Activate valid indices\n",
    "        for synset in synsets:\n",
    "            s_name = synset.name()\n",
    "            if s_name in self.label2id:\n",
    "                idx_to_activate = self.label2id[s_name]\n",
    "                mask[idx_to_activate] = 0.0\n",
    "                found_candidates = True\n",
    "                valid_candidate_ids.append(idx_to_activate)\n",
    "        \n",
    "        # 3. If no candidates found, unmask all logits \n",
    "        if not found_candidates:\n",
    "            mask = torch.zeros((self.num_labels,), dtype=torch.float32)\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'target_token_idx': torch.tensor(target_token_idx, dtype=torch.long),\n",
    "            'logit_mask': mask\n",
    "        }\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d0566a9-9662-403a-bfc4-5e6999e9af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Custom Model Class ---\n",
    "class DebertaV3ForWSD(DebertaV2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.deberta = AutoModel.from_config(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, target_token_idx=None, labels=None, logit_mask=None, **kwargs):\n",
    "        kwargs.pop(\"num_items_in_batch\", None)\n",
    "\n",
    "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "        batch_indices = torch.arange(batch_size, device=input_ids.device)\n",
    "\n",
    "        # Extract vector for the specific target token\n",
    "        target_vectors = sequence_output[batch_indices, target_token_idx]\n",
    "\n",
    "        target_vectors = self.dropout(target_vectors)\n",
    "        logits = self.classifier(target_vectors)\n",
    "\n",
    "        # --- Apply Logit Masking ---\n",
    "        if logit_mask is not None:\n",
    "            logits = logits + logit_mask\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b110f71f-f93f-4b59-95cb-7ca272e4385d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Setup Paths and Device ---\n",
    "model_path = \"./models/deberta_masked/deberta_wsd_masked\"\n",
    "test_data_path = \"./evaluation_data/parquet/ALL.parquet\"\n",
    "label_map_path = \"./label_map.json\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb9b7218-bdc4-4265-94e8-620518324b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Load Resources ---\n",
    "# Load Label Map\n",
    "with open(label_map_path, 'r', encoding='utf-8') as f:\n",
    "    label2id = json.load(f)\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Load Tokenizer & Config\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = DebertaV2Config.from_pretrained(model_path)\n",
    "\n",
    "# Load Model\n",
    "model = DebertaV3ForWSD.from_pretrained(model_path, config=config)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load Data\n",
    "df_test = pd.read_parquet(test_data_path)\n",
    "\n",
    "# Create Dataset & Loader\n",
    "dataset = WSDDataset(df_test, tokenizer, label2id)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2977931-d846-4861-b6bf-59e58f216052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference with Logit Masking...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c4510b4a534dd6aace5cca045013da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 5. Inference Loop ---\n",
    "all_preds = []\n",
    "all_masks_str = [] # To store readable masks\n",
    "\n",
    "print(\"Running inference with Logit Masking...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        target_token_idx = batch['target_token_idx'].to(device)\n",
    "        logit_mask = batch['logit_mask'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            target_token_idx=target_token_idx,\n",
    "            logit_mask=logit_mask\n",
    "        )\n",
    "        \n",
    "        # Get predictions\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        \n",
    "        # Recover used masks for reporting\n",
    "        # We look at logit_mask: 0.0 means active, -10000 means masked\n",
    "        batch_masks = logit_mask.cpu().numpy()\n",
    "        for mask_row in batch_masks:\n",
    "            # Find indices where mask is 0.0 (or close to it)\n",
    "            active_indices = np.where(mask_row > -100.0)[0]\n",
    "            \n",
    "            if len(active_indices) == len(mask_row):\n",
    "                # If all are active, it was a fallback (no candidates found)\n",
    "                all_masks_str.append(\"ALL_LABELS (Fallback)\")\n",
    "            else:\n",
    "                # Convert indices to string labels\n",
    "                active_labels = [id2label[idx] for idx in active_indices]\n",
    "                all_masks_str.append(active_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7694cd30-6aab-4ddc-b2e3-9a5df815095a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy with Masking: 0.6495 (4711/7253)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>gold_synsets</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>logit_mask_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>senseval2.d000.s000.t000</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>art</td>\n",
       "      <td>[art.n.03]</td>\n",
       "      <td>art.n.01</td>\n",
       "      <td>False</td>\n",
       "      <td>[art.n.01, art.n.02, art.n.03, artwork.n.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>senseval2.d000.s000.t001</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>change-ringing</td>\n",
       "      <td>[change_ringing.n.01]</td>\n",
       "      <td>pickup.n.01</td>\n",
       "      <td>False</td>\n",
       "      <td>ALL_LABELS (Fallback)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>senseval2.d000.s000.t002</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>peculiar</td>\n",
       "      <td>[particular.s.01, peculiar.s.04]</td>\n",
       "      <td>particular.s.01</td>\n",
       "      <td>True</td>\n",
       "      <td>[curious.s.01, particular.s.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>senseval2.d000.s000.t003</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>English</td>\n",
       "      <td>[english.n.02]</td>\n",
       "      <td>english.a.01</td>\n",
       "      <td>False</td>\n",
       "      <td>[english.a.01, english.n.01, english.n.02, eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>senseval2.d000.s000.t004</td>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>most</td>\n",
       "      <td>[most.a.01]</td>\n",
       "      <td>most.a.01</td>\n",
       "      <td>True</td>\n",
       "      <td>[about.r.07, most.a.01, most.a.02, most.r.01, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  senseval2.d000.s000.t000   \n",
       "1  senseval2.d000.s000.t001   \n",
       "2  senseval2.d000.s000.t002   \n",
       "3  senseval2.d000.s000.t003   \n",
       "4  senseval2.d000.s000.t004   \n",
       "\n",
       "                                            sentence     target_word  \\\n",
       "0  The art of change-ringing is peculiar to the E...             art   \n",
       "1  The art of change-ringing is peculiar to the E...  change-ringing   \n",
       "2  The art of change-ringing is peculiar to the E...        peculiar   \n",
       "3  The art of change-ringing is peculiar to the E...         English   \n",
       "4  The art of change-ringing is peculiar to the E...            most   \n",
       "\n",
       "                       gold_synsets  predicted_label  is_correct  \\\n",
       "0                        [art.n.03]         art.n.01       False   \n",
       "1             [change_ringing.n.01]      pickup.n.01       False   \n",
       "2  [particular.s.01, peculiar.s.04]  particular.s.01        True   \n",
       "3                    [english.n.02]     english.a.01       False   \n",
       "4                       [most.a.01]        most.a.01        True   \n",
       "\n",
       "                               logit_mask_candidates  \n",
       "0       [art.n.01, art.n.02, art.n.03, artwork.n.01]  \n",
       "1                              ALL_LABELS (Fallback)  \n",
       "2                    [curious.s.01, particular.s.01]  \n",
       "3  [english.a.01, english.n.01, english.n.02, eng...  \n",
       "4  [about.r.07, most.a.01, most.a.02, most.r.01, ...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 6. Build Results & Calculate Accuracy ---\n",
    "results = []\n",
    "correct_count = 0\n",
    "total_count = len(df_test)\n",
    "\n",
    "for idx, row in df_test.iterrows():\n",
    "    pred_id = all_preds[idx]\n",
    "    pred_label = id2label.get(pred_id, \"UNKNOWN\")\n",
    "    mask_used = all_masks_str[idx]\n",
    "    \n",
    "    gold_list = row['gold_synsets']\n",
    "    is_correct = pred_label in gold_list\n",
    "    \n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "        \n",
    "    # Build row\n",
    "    res_row = row.drop(['char_start', 'char_end']).to_dict()\n",
    "    res_row['predicted_label'] = pred_label\n",
    "    res_row['is_correct'] = is_correct\n",
    "    res_row['logit_mask_candidates'] = mask_used\n",
    "    \n",
    "    results.append(res_row)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0.0\n",
    "print(f\"\\nModel Accuracy with Masking: {accuracy:.4f} ({correct_count}/{total_count})\")\n",
    "\n",
    "# Create Final DataFrame\n",
    "final_df = pd.DataFrame(results)\n",
    "final_df['gold_synsets'] = final_df['gold_synsets'].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)\n",
    "final_df.to_csv(\"./results/masked_results.csv\", index=False)\n",
    "\n",
    "# Display result\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da04b3-71c5-4384-ace0-28c9486e6f7b",
   "metadata": {},
   "source": [
    "## Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d4727c8-794b-431c-9972-bc5c4e0a90b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unmasked = pd.read_csv(\"./results/unmasked_results.csv\")\n",
    "df_masked = pd.read_csv(\"./results/masked_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a191a2b-87ab-4d44-9d64-5b4f73595722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged dataframe: (7253, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>gold_synsets</th>\n",
       "      <th>unmasked_predicted_label</th>\n",
       "      <th>unmasked_is_correct</th>\n",
       "      <th>masked_predicted_label</th>\n",
       "      <th>masked_is_correct</th>\n",
       "      <th>masked_logit_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>art</td>\n",
       "      <td>['art.n.03']</td>\n",
       "      <td>art.n.01</td>\n",
       "      <td>False</td>\n",
       "      <td>art.n.01</td>\n",
       "      <td>False</td>\n",
       "      <td>['art.n.01', 'art.n.02', 'art.n.03', 'artwork....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>change-ringing</td>\n",
       "      <td>['change_ringing.n.01']</td>\n",
       "      <td>change.n.03</td>\n",
       "      <td>False</td>\n",
       "      <td>pickup.n.01</td>\n",
       "      <td>False</td>\n",
       "      <td>ALL_LABELS (Fallback)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>peculiar</td>\n",
       "      <td>['particular.s.01', 'peculiar.s.04']</td>\n",
       "      <td>particular.s.01</td>\n",
       "      <td>True</td>\n",
       "      <td>particular.s.01</td>\n",
       "      <td>True</td>\n",
       "      <td>['curious.s.01', 'particular.s.01']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>English</td>\n",
       "      <td>['english.n.02']</td>\n",
       "      <td>english.n.01</td>\n",
       "      <td>False</td>\n",
       "      <td>english.a.01</td>\n",
       "      <td>False</td>\n",
       "      <td>['english.a.01', 'english.n.01', 'english.n.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>most</td>\n",
       "      <td>['most.a.01']</td>\n",
       "      <td>most.a.01</td>\n",
       "      <td>True</td>\n",
       "      <td>most.a.01</td>\n",
       "      <td>True</td>\n",
       "      <td>['about.r.07', 'most.a.01', 'most.a.02', 'most...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence     target_word  \\\n",
       "0  The art of change-ringing is peculiar to the E...             art   \n",
       "1  The art of change-ringing is peculiar to the E...  change-ringing   \n",
       "2  The art of change-ringing is peculiar to the E...        peculiar   \n",
       "3  The art of change-ringing is peculiar to the E...         English   \n",
       "4  The art of change-ringing is peculiar to the E...            most   \n",
       "\n",
       "                           gold_synsets unmasked_predicted_label  \\\n",
       "0                          ['art.n.03']                 art.n.01   \n",
       "1               ['change_ringing.n.01']              change.n.03   \n",
       "2  ['particular.s.01', 'peculiar.s.04']          particular.s.01   \n",
       "3                      ['english.n.02']             english.n.01   \n",
       "4                         ['most.a.01']                most.a.01   \n",
       "\n",
       "   unmasked_is_correct masked_predicted_label  masked_is_correct  \\\n",
       "0                False               art.n.01              False   \n",
       "1                False            pickup.n.01              False   \n",
       "2                 True        particular.s.01               True   \n",
       "3                False           english.a.01              False   \n",
       "4                 True              most.a.01               True   \n",
       "\n",
       "                             masked_logit_candidates  \n",
       "0  ['art.n.01', 'art.n.02', 'art.n.03', 'artwork....  \n",
       "1                              ALL_LABELS (Fallback)  \n",
       "2                ['curious.s.01', 'particular.s.01']  \n",
       "3  ['english.a.01', 'english.n.01', 'english.n.02...  \n",
       "4  ['about.r.07', 'most.a.01', 'most.a.02', 'most...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Rename columns in the unmasked dataframe\n",
    "df_unmasked_ready = df_unmasked.copy().rename(columns={\n",
    "    'predicted_label': 'unmasked_predicted_label',\n",
    "    'is_correct': 'unmasked_is_correct'\n",
    "})\n",
    "\n",
    "# 2. Rename columns in the masked dataframe\n",
    "df_masked_ready = df_masked.copy().rename(columns={\n",
    "    'predicted_label': 'masked_predicted_label',\n",
    "    'is_correct': 'masked_is_correct',\n",
    "    'logit_mask_candidates': 'masked_logit_candidates'\n",
    "})\n",
    "\n",
    "# 3. Define which columns to take from the masked dataframe\n",
    "# We only need 'id' for the join key and the specific result columns.\n",
    "# We skip 'sentence', 'target_word', etc., because they are already in the first dataframe.\n",
    "columns_to_merge = [\n",
    "    'id', \n",
    "    'masked_predicted_label', \n",
    "    'masked_is_correct', \n",
    "    'masked_logit_candidates'\n",
    "]\n",
    "\n",
    "# 4. Merge the dataframes\n",
    "merged_df = pd.merge(\n",
    "    df_unmasked_ready, \n",
    "    df_masked_ready[columns_to_merge], \n",
    "    on='id', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Drop \"id\" column\n",
    "merged_df = merged_df.drop([\"id\"], axis=1)\n",
    "\n",
    "# Display results\n",
    "print(f\"Shape of merged dataframe: {merged_df.shape}\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc51f9-f7bc-4943-a3d2-dd76c9ececae",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65984e3a-5545-4b2e-bbf3-041bfa081f7f",
   "metadata": {},
   "source": [
    "> Compare the model with and without using the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b23df02-ddbe-4a67-bd23-f9d8d63ddfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance Comparison Summary ---\n",
      "Cases where Unmasked model won (Masking hurt):    321\n",
      "Cases where Masked model won (Masking improved):  771\n",
      "Net Improvement (Masked wins - Unmasked wins):    450\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Boolean masks for the comparison cases\n",
    "unmasked_better_mask = (merged_df['unmasked_is_correct'] == True) & (merged_df['masked_is_correct'] == False)\n",
    "masked_better_mask = (merged_df['masked_is_correct'] == True) & (merged_df['unmasked_is_correct'] == False)\n",
    "\n",
    "# 2. Calculate counts\n",
    "count_unmasked_better = unmasked_better_mask.sum()\n",
    "count_masked_better = masked_better_mask.sum()\n",
    "\n",
    "# 3. Print Summary Statistics\n",
    "print(\"--- Performance Comparison Summary ---\")\n",
    "print(f\"Cases where Unmasked model won (Masking hurt):    {count_unmasked_better}\")\n",
    "print(f\"Cases where Masked model won (Masking improved):  {count_masked_better}\")\n",
    "\n",
    "net_improvement = count_masked_better - count_unmasked_better\n",
    "print(f\"Net Improvement (Masked wins - Unmasked wins):    {net_improvement}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baa68545-14cd-454b-a809-6d8a3803e9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLES: Unmasked model Correct vs Masked model Incorrect (Count: 321)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>gold_synsets</th>\n",
       "      <th>unmasked_predicted_label</th>\n",
       "      <th>unmasked_is_correct</th>\n",
       "      <th>masked_predicted_label</th>\n",
       "      <th>masked_is_correct</th>\n",
       "      <th>masked_logit_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Now , only one local ringer remains : 64-year-...</td>\n",
       "      <td>Now</td>\n",
       "      <td>['nowadays.r.01']</td>\n",
       "      <td>nowadays.r.01</td>\n",
       "      <td>True</td>\n",
       "      <td>now.r.01</td>\n",
       "      <td>False</td>\n",
       "      <td>['immediately.r.01', 'now.n.01', 'now.r.01', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>History , after all , is not on his side .</td>\n",
       "      <td>History</td>\n",
       "      <td>['history.n.01']</td>\n",
       "      <td>history.n.01</td>\n",
       "      <td>True</td>\n",
       "      <td>history.n.03</td>\n",
       "      <td>False</td>\n",
       "      <td>['history.n.01', 'history.n.02', 'history.n.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>According to a nationwide survey taken a year ...</td>\n",
       "      <td>ring</td>\n",
       "      <td>['ring.v.03']</td>\n",
       "      <td>ring.v.03</td>\n",
       "      <td>True</td>\n",
       "      <td>call.v.03</td>\n",
       "      <td>False</td>\n",
       "      <td>['call.v.03', 'gang.n.01', 'hoop.n.02', 'resou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>It is easy to see why the ancient art is on th...</td>\n",
       "      <td>ancient</td>\n",
       "      <td>['ancient.s.01']</td>\n",
       "      <td>ancient.s.01</td>\n",
       "      <td>True</td>\n",
       "      <td>ancient.s.02</td>\n",
       "      <td>False</td>\n",
       "      <td>['ancient.s.01', 'ancient.s.02']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>The less complicated version of playing tunes ...</td>\n",
       "      <td>playing</td>\n",
       "      <td>['play.v.06']</td>\n",
       "      <td>play.v.06</td>\n",
       "      <td>True</td>\n",
       "      <td>play.v.03</td>\n",
       "      <td>False</td>\n",
       "      <td>['act.v.03', 'act.v.05', 'act.v.10', 'acting.n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence target_word  \\\n",
       "75   Now , only one local ringer remains : 64-year-...         Now   \n",
       "126         History , after all , is not on his side .     History   \n",
       "141  According to a nationwide survey taken a year ...        ring   \n",
       "144  It is easy to see why the ancient art is on th...     ancient   \n",
       "149  The less complicated version of playing tunes ...     playing   \n",
       "\n",
       "          gold_synsets unmasked_predicted_label  unmasked_is_correct  \\\n",
       "75   ['nowadays.r.01']            nowadays.r.01                 True   \n",
       "126   ['history.n.01']             history.n.01                 True   \n",
       "141      ['ring.v.03']                ring.v.03                 True   \n",
       "144   ['ancient.s.01']             ancient.s.01                 True   \n",
       "149      ['play.v.06']                play.v.06                 True   \n",
       "\n",
       "    masked_predicted_label  masked_is_correct  \\\n",
       "75                now.r.01              False   \n",
       "126           history.n.03              False   \n",
       "141              call.v.03              False   \n",
       "144           ancient.s.02              False   \n",
       "149              play.v.03              False   \n",
       "\n",
       "                               masked_logit_candidates  \n",
       "75   ['immediately.r.01', 'now.n.01', 'now.r.01', '...  \n",
       "126  ['history.n.01', 'history.n.02', 'history.n.03...  \n",
       "141  ['call.v.03', 'gang.n.01', 'hoop.n.02', 'resou...  \n",
       "144                   ['ancient.s.01', 'ancient.s.02']  \n",
       "149  ['act.v.03', 'act.v.05', 'act.v.10', 'acting.n...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 4. Display Examples ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"EXAMPLES: Unmasked model Correct vs Masked model Incorrect (Count: {count_unmasked_better})\")\n",
    "print(\"=\"*80)\n",
    "df_unmasked_wins = merged_df[unmasked_better_mask]\n",
    "display(df_unmasked_wins.head(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61ab2bd7-b414-4896-962a-3970ff536fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLES: Masked model Correct vs Unmasked model Incorrect (Count: 771)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>gold_synsets</th>\n",
       "      <th>unmasked_predicted_label</th>\n",
       "      <th>unmasked_is_correct</th>\n",
       "      <th>masked_predicted_label</th>\n",
       "      <th>masked_is_correct</th>\n",
       "      <th>masked_logit_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The art of change-ringing is peculiar to the E...</td>\n",
       "      <td>peculiarities</td>\n",
       "      <td>['peculiarity.n.01', 'peculiarity.n.02']</td>\n",
       "      <td>curious.s.01</td>\n",
       "      <td>False</td>\n",
       "      <td>peculiarity.n.01</td>\n",
       "      <td>True</td>\n",
       "      <td>['curio.n.01', 'peculiarity.n.01', 'peculiarit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Of all scenes that evoke rural England , this ...</td>\n",
       "      <td>ancient</td>\n",
       "      <td>['ancient.s.02']</td>\n",
       "      <td>ancient.s.01</td>\n",
       "      <td>False</td>\n",
       "      <td>ancient.s.02</td>\n",
       "      <td>True</td>\n",
       "      <td>['ancient.s.01', 'ancient.s.02']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Of all scenes that evoke rural England , this ...</td>\n",
       "      <td>cascading</td>\n",
       "      <td>['cascade.v.01']</td>\n",
       "      <td>pour.v.02</td>\n",
       "      <td>False</td>\n",
       "      <td>cascade.v.01</td>\n",
       "      <td>True</td>\n",
       "      <td>['cascade.v.01']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The parishioners of St. Michael and All Angels...</td>\n",
       "      <td>parishioners</td>\n",
       "      <td>['parishioner.n.01']</td>\n",
       "      <td>resident.n.01</td>\n",
       "      <td>False</td>\n",
       "      <td>parishioner.n.01</td>\n",
       "      <td>True</td>\n",
       "      <td>['parishioner.n.01']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>In the tower , five men and women pull rhythmi...</td>\n",
       "      <td>ropes</td>\n",
       "      <td>['rope.n.01']</td>\n",
       "      <td>wire.n.01</td>\n",
       "      <td>False</td>\n",
       "      <td>rope.n.01</td>\n",
       "      <td>True</td>\n",
       "      <td>['rope.n.01']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence    target_word  \\\n",
       "6   The art of change-ringing is peculiar to the E...  peculiarities   \n",
       "17  Of all scenes that evoke rural England , this ...        ancient   \n",
       "24  Of all scenes that evoke rural England , this ...      cascading   \n",
       "29  The parishioners of St. Michael and All Angels...   parishioners   \n",
       "42  In the tower , five men and women pull rhythmi...          ropes   \n",
       "\n",
       "                                gold_synsets unmasked_predicted_label  \\\n",
       "6   ['peculiarity.n.01', 'peculiarity.n.02']             curious.s.01   \n",
       "17                          ['ancient.s.02']             ancient.s.01   \n",
       "24                          ['cascade.v.01']                pour.v.02   \n",
       "29                      ['parishioner.n.01']            resident.n.01   \n",
       "42                             ['rope.n.01']                wire.n.01   \n",
       "\n",
       "    unmasked_is_correct masked_predicted_label  masked_is_correct  \\\n",
       "6                 False       peculiarity.n.01               True   \n",
       "17                False           ancient.s.02               True   \n",
       "24                False           cascade.v.01               True   \n",
       "29                False       parishioner.n.01               True   \n",
       "42                False              rope.n.01               True   \n",
       "\n",
       "                              masked_logit_candidates  \n",
       "6   ['curio.n.01', 'peculiarity.n.01', 'peculiarit...  \n",
       "17                   ['ancient.s.01', 'ancient.s.02']  \n",
       "24                                   ['cascade.v.01']  \n",
       "29                               ['parishioner.n.01']  \n",
       "42                                      ['rope.n.01']  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"EXAMPLES: Masked model Correct vs Unmasked model Incorrect (Count: {count_masked_better})\")\n",
    "print(\"=\"*80)\n",
    "df_masked_wins = merged_df[masked_better_mask]\n",
    "display(df_masked_wins.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd84c76-d901-4606-a624-a9aab4737976",
   "metadata": {},
   "source": [
    "> Analysis of errors depending on the availability of the correct answer in the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9379408-005b-41ab-9a0c-a89ea567732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gold_availability(row):\n",
    "    \"\"\"\n",
    "    Checks if at least one gold synset exists in the masked candidates list.\n",
    "    \"\"\"\n",
    "    candidates = row['masked_logit_candidates']\n",
    "    gold_synsets = row['gold_synsets']\n",
    "    \n",
    "    # --- Normalize Candidates (Mask) ---\n",
    "    if isinstance(candidates, str):\n",
    "        if \"ALL_LABELS (Fallback)\" in candidates:\n",
    "            return True\n",
    "        \n",
    "        # 2. Parse string representation\n",
    "        try:\n",
    "            candidates = ast.literal_eval(candidates)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return False\n",
    "\n",
    "    # --- Normalize Gold Synsets ---\n",
    "    if isinstance(gold_synsets, str):\n",
    "        try:\n",
    "            gold_synsets = ast.literal_eval(gold_synsets)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # --- Check Intersection ---\n",
    "    # Ensure inputs are sets for comparison\n",
    "    if candidates is None: return False\n",
    "    \n",
    "    gold_set = set(gold_synsets)\n",
    "    candidate_set = set(candidates)\n",
    "    \n",
    "    # Return True if there is ANY common element\n",
    "    return not gold_set.isdisjoint(candidate_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "615d3367-e745-4161-a9a1-1acbfda69365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "merged_df['gold_available_in_mask'] = merged_df.apply(check_gold_availability, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21f47f26-d03d-4363-94b3-b1fce1eaf335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      " COMPARISON REPORT \n",
      "========================================\n",
      "Gold label MISSING from candidates:  460 (Impossible to solve)\n",
      "Gold label AVAILABLE but predicted wrong: 2082\n"
     ]
    }
   ],
   "source": [
    "# Mask Validity Stats\n",
    "# Gold was NOT in the mask (missing in train or NLTK failure)\n",
    "missing_gold_count = len(merged_df[merged_df['gold_available_in_mask'] == False])\n",
    "\n",
    "# Gold WAS in the mask, but model still failed\n",
    "present_but_wrong_count = len(merged_df[\n",
    "    (merged_df['gold_available_in_mask'] == True) & \n",
    "    (merged_df['masked_is_correct'] == False)\n",
    "])\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\" COMPARISON REPORT \")\n",
    "print(\"=\"*40)\n",
    "print(f\"Gold label MISSING from candidates:  {missing_gold_count} (Impossible to solve)\")\n",
    "print(f\"Gold label AVAILABLE but predicted wrong: {present_but_wrong_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30887cae-3421-4730-8adb-005f87a86198",
   "metadata": {},
   "source": [
    "> Cases of errors in the model with a mask, when the correct answer was in the mask, and the model without a mask answered correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6bb5a901-86c3-44c8-a3af-757dacbe3f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>gold_synsets</th>\n",
       "      <th>unmasked_predicted_label</th>\n",
       "      <th>unmasked_is_correct</th>\n",
       "      <th>masked_predicted_label</th>\n",
       "      <th>masked_is_correct</th>\n",
       "      <th>masked_logit_candidates</th>\n",
       "      <th>gold_available_in_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Now , only one local ringer remains : 64-year-...</td>\n",
       "      <td>Now</td>\n",
       "      <td>['nowadays.r.01']</td>\n",
       "      <td>nowadays.r.01</td>\n",
       "      <td>True</td>\n",
       "      <td>now.r.01</td>\n",
       "      <td>False</td>\n",
       "      <td>['immediately.r.01', 'now.n.01', 'now.r.01', '...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>History , after all , is not on his side .</td>\n",
       "      <td>History</td>\n",
       "      <td>['history.n.01']</td>\n",
       "      <td>history.n.01</td>\n",
       "      <td>True</td>\n",
       "      <td>history.n.03</td>\n",
       "      <td>False</td>\n",
       "      <td>['history.n.01', 'history.n.02', 'history.n.03...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>According to a nationwide survey taken a year ...</td>\n",
       "      <td>ring</td>\n",
       "      <td>['ring.v.03']</td>\n",
       "      <td>ring.v.03</td>\n",
       "      <td>True</td>\n",
       "      <td>call.v.03</td>\n",
       "      <td>False</td>\n",
       "      <td>['call.v.03', 'gang.n.01', 'hoop.n.02', 'resou...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>It is easy to see why the ancient art is on th...</td>\n",
       "      <td>ancient</td>\n",
       "      <td>['ancient.s.01']</td>\n",
       "      <td>ancient.s.01</td>\n",
       "      <td>True</td>\n",
       "      <td>ancient.s.02</td>\n",
       "      <td>False</td>\n",
       "      <td>['ancient.s.01', 'ancient.s.02']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>The less complicated version of playing tunes ...</td>\n",
       "      <td>playing</td>\n",
       "      <td>['play.v.06']</td>\n",
       "      <td>play.v.06</td>\n",
       "      <td>True</td>\n",
       "      <td>play.v.03</td>\n",
       "      <td>False</td>\n",
       "      <td>['act.v.03', 'act.v.05', 'act.v.10', 'acting.n...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence target_word  \\\n",
       "75   Now , only one local ringer remains : 64-year-...         Now   \n",
       "126         History , after all , is not on his side .     History   \n",
       "141  According to a nationwide survey taken a year ...        ring   \n",
       "144  It is easy to see why the ancient art is on th...     ancient   \n",
       "149  The less complicated version of playing tunes ...     playing   \n",
       "\n",
       "          gold_synsets unmasked_predicted_label  unmasked_is_correct  \\\n",
       "75   ['nowadays.r.01']            nowadays.r.01                 True   \n",
       "126   ['history.n.01']             history.n.01                 True   \n",
       "141      ['ring.v.03']                ring.v.03                 True   \n",
       "144   ['ancient.s.01']             ancient.s.01                 True   \n",
       "149      ['play.v.06']                play.v.06                 True   \n",
       "\n",
       "    masked_predicted_label  masked_is_correct  \\\n",
       "75                now.r.01              False   \n",
       "126           history.n.03              False   \n",
       "141              call.v.03              False   \n",
       "144           ancient.s.02              False   \n",
       "149              play.v.03              False   \n",
       "\n",
       "                               masked_logit_candidates  gold_available_in_mask  \n",
       "75   ['immediately.r.01', 'now.n.01', 'now.r.01', '...                    True  \n",
       "126  ['history.n.01', 'history.n.02', 'history.n.03...                    True  \n",
       "141  ['call.v.03', 'gang.n.01', 'hoop.n.02', 'resou...                    True  \n",
       "144                   ['ancient.s.01', 'ancient.s.02']                    True  \n",
       "149  ['act.v.03', 'act.v.05', 'act.v.10', 'acting.n...                    True  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (merged_df['masked_is_correct'] == False) & (merged_df['unmasked_is_correct'] == True) & (merged_df['gold_available_in_mask'] == True)\n",
    "display(mask.sum())\n",
    "merged_df[mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c1c3cf-ea3f-46a8-8ed0-a0c4ff8180e0",
   "metadata": {},
   "source": [
    "> There are 315/321 such cases (where the model without a mask outperformed the model with a mask), which can generally be understood as the model with a mask being more effective because it restricts the prediction space and selects the class with the highest probability from the POSSIBLE ones, but the model without a mask learns in more complex conditions, as it selects from ALL possible classes, which in some cases allows it to predict the correct class with high confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3afe470-d7c6-49da-8d05-19a58a64fcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
