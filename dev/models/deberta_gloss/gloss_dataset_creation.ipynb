{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30176eb-0770-4266-b649-2492ba589383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.data.path.append(\"./nltk_data\")\n",
    "from nltk.corpus import wordnet as wn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd53f5f7-74f9-4409-b11d-2eef2694fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_target_word(text, char_start, char_end, marker_start=\"[TGT]\", marker_end=\"[TGT]\"):\n",
    "    \"\"\"\n",
    "    Wraps the target word in the sentence with special markers.\n",
    "    Example: \"The [TGT] bank [TGT] is closed.\"\n",
    "    \"\"\"     \n",
    "    return text[:char_start] + marker_start + text[char_start:char_end] + marker_end + text[char_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3966791c-e30c-43b5-add8-3c0b56f4e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_gloss_dataset(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Converts standard dataset into Gloss dataset.\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(input_path)\n",
    "    \n",
    "    new_rows = []\n",
    "    \n",
    "    print(f\"Processing {len(df)} rows from {input_path}...\")\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        sentence = row['sentence']\n",
    "        target_word = row['target_word']\n",
    "        true_label_name = row['label'] # e.g., 'group.n.01'\n",
    "        \n",
    "        # 1. Create context with markers to focus attention\n",
    "        # Using [TGT] as a marker.\n",
    "        context_with_markers = mark_target_word(\n",
    "            sentence, \n",
    "            row['char_start'], \n",
    "            row['char_end'],\n",
    "            marker_start=\" [TGT] \", \n",
    "            marker_end=\" [TGT] \"\n",
    "        )\n",
    "        \n",
    "        # 2. Get all candidate synsets from WordNet\n",
    "        # Replace spaces with underscores for lookup if it's a multi-word expression\n",
    "        lookup_word = target_word.replace(\" \", \"_\")\n",
    "        candidates = wn.synsets(lookup_word)\n",
    "        \n",
    "        if not candidates:\n",
    "            # For simplicity, I skip if no candidates found i.e. skip all NE - Named Entities.\n",
    "            continue\n",
    "            \n",
    "        # Unique ID for this specific instance (sentence + position)\n",
    "        # This is crucial for splitting train/val later without leakage\n",
    "        instance_group_id = f\"{row['sentence_id']}_{row['char_start']}\"\n",
    "\n",
    "        current_word_rows = []\n",
    "        has_positive = False\n",
    "        \n",
    "        for synset in candidates:\n",
    "            synset_name = synset.name()\n",
    "            \n",
    "            # 3. Handle missing definition\n",
    "            gloss = synset.definition()\n",
    "            if not gloss or len(gloss.strip()) == 0:\n",
    "                # Fallback: Use lemma names as definition\n",
    "                gloss = \", \".join([lemma.name().replace(\"_\", \" \") for lemma in synset.lemmas()])\n",
    "            \n",
    "            # 4. Determine label (Binary: 1 if matches true label, else 0)\n",
    "            label = 1 if synset_name == true_label_name else 0\n",
    "            \n",
    "            if label == 1:\n",
    "                has_positive = True\n",
    "\n",
    "            current_word_rows.append({\n",
    "                'instance_group_id': instance_group_id,\n",
    "                'context': context_with_markers,\n",
    "                'gloss': gloss,\n",
    "                'candidate_synset': synset_name,\n",
    "                'label': label\n",
    "            })\n",
    "            \n",
    "        if has_positive:\n",
    "            new_rows.extend(current_word_rows)\n",
    "\n",
    "    gloss_df = pd.DataFrame(new_rows)\n",
    "    \n",
    "    print(f\"Created {len(gloss_df)} gloss-context pairs.\")\n",
    "    print(f\"Positive samples: {gloss_df['label'].sum()}\")\n",
    "    \n",
    "    gloss_df.to_parquet(output_path)\n",
    "    print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d38639-1f72-4359-8a7d-512728242f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 224515 rows from semcor_train.parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 224515/224515 [00:38<00:00, 5845.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1925220 gloss-context pairs.\n",
      "Positive samples: 210495\n",
      "Saved to semcor_gloss_train.parquet\n"
     ]
    }
   ],
   "source": [
    "prepare_gloss_dataset(\"semcor_train.parquet\", \"semcor_gloss_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c6499-0882-4b79-8cf5-c04ef3dad013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a55e30-f916-4849-a43f-8e91bd902494",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"semcor_gloss_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac435d8b-fb08-4019-9305-c1758452dde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_group_id</th>\n",
       "      <th>context</th>\n",
       "      <th>gloss</th>\n",
       "      <th>candidate_synset</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_29</td>\n",
       "      <td>The Fulton County Grand Jury  [TGT] said [TGT]...</td>\n",
       "      <td>express in words</td>\n",
       "      <td>state.v.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_29</td>\n",
       "      <td>The Fulton County Grand Jury  [TGT] said [TGT]...</td>\n",
       "      <td>report or maintain</td>\n",
       "      <td>allege.v.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_29</td>\n",
       "      <td>The Fulton County Grand Jury  [TGT] said [TGT]...</td>\n",
       "      <td>express a supposition</td>\n",
       "      <td>suppose.v.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_29</td>\n",
       "      <td>The Fulton County Grand Jury  [TGT] said [TGT]...</td>\n",
       "      <td>have or contain a certain wording or form</td>\n",
       "      <td>read.v.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_29</td>\n",
       "      <td>The Fulton County Grand Jury  [TGT] said [TGT]...</td>\n",
       "      <td>give instructions to or direct somebody to do ...</td>\n",
       "      <td>order.v.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  instance_group_id                                            context  \\\n",
       "0              0_29  The Fulton County Grand Jury  [TGT] said [TGT]...   \n",
       "1              0_29  The Fulton County Grand Jury  [TGT] said [TGT]...   \n",
       "2              0_29  The Fulton County Grand Jury  [TGT] said [TGT]...   \n",
       "3              0_29  The Fulton County Grand Jury  [TGT] said [TGT]...   \n",
       "4              0_29  The Fulton County Grand Jury  [TGT] said [TGT]...   \n",
       "\n",
       "                                               gloss candidate_synset  label  \n",
       "0                                   express in words       state.v.01      1  \n",
       "1                                 report or maintain      allege.v.01      0  \n",
       "2                              express a supposition     suppose.v.01      0  \n",
       "3          have or contain a certain wording or form        read.v.02      0  \n",
       "4  give instructions to or direct somebody to do ...       order.v.01      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
